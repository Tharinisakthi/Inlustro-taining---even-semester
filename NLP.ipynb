{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkS5eCuiiI1vr95Js8FaoW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tharinisakthi/Inlustro-taining---even-semester/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Win1Fe-qbJCq",
        "outputId": "835885ba-e8fa-40cb-db25-cdcf3117b290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text=\"The striped bats are hanging on their feet and talking,Running, files, better, cared, studying\"\n",
        "tokens=word_tokenize(text)\n",
        "print(\"original Tokens:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0HTNMoAbZaO",
        "outputId": "986e9222-da62-4419-d8b7-8c6cccc4e439"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original Tokens: ['The', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet', 'and', 'talking', ',', 'Running', ',', 'files', ',', 'better', ',', 'cared', ',', 'studying']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "porter=PorterStemmer()\n",
        "stemmed_words=[porter.stem(word) for word in tokens]\n",
        "print(\"Porter Steamer:\", stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlvxWe8zbdYm",
        "outputId": "b463d1ac-35c6-43d9-95cc-8eb3ac676ca1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Porter Steamer: ['the', 'stripe', 'bat', 'are', 'hang', 'on', 'their', 'feet', 'and', 'talk', ',', 'run', ',', 'file', ',', 'better', ',', 'care', ',', 'studi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "lemmatized_words=[lemmatizer.lemmatize(word) for word in tokens]\n",
        "print(\"Lemmatizer Words:\", lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y25GMWoxbhl6",
        "outputId": "4ac2071a-0a3a-4acc-ecc9-984ff2bb6524"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatizer Words: ['The', 'striped', 'bat', 'are', 'hanging', 'on', 'their', 'foot', 'and', 'talking', ',', 'Running', ',', 'file', ',', 'better', ',', 'cared', ',', 'studying']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokens=[word.lower() for word in tokens]\n",
        "print(\"Lowercase Tokens:\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_b-SlQUbnVn",
        "outputId": "81ed8654-023f-4840-c2a4-e19069b2b1d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowercase Tokens: ['the', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet', 'and', 'talking', ',', 'running', ',', 'files', ',', 'better', ',', 'cared', ',', 'studying']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "default_stopwords=set(stopwords.words('english'))\n",
        "default_filtered_tokens=[word for word in tokens if word not in default_stopwords]\n",
        "print(\"Tokens after removing default stopwords:\", default_filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bznqKMTGbr_P",
        "outputId": "0cba2418-18a1-43b3-acd8-250f997fb7b1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens after removing default stopwords: ['striped', 'bats', 'hanging', 'feet', 'talking', ',', 'running', ',', 'files', ',', 'better', ',', 'cared', ',', 'studying']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "custom_stopwords={\"striped\",\"bats\",\".\"}\n",
        "custom_filtered_tokens=[word for word in default_filtered_tokens if word not in custom_stopwords]\n",
        "print(\"Tokens after removing custom stopwords:\", custom_filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoCU4LnVbvbD",
        "outputId": "dce90510-1f6a-4ee0-bb90-725cd4b16654"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens after removing custom stopwords: ['hanging', 'feet', 'talking', ',', 'running', ',', 'files', ',', 'better', ',', 'cared', ',', 'studying']\n"
          ]
        }
      ]
    }
  ]
}